{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppx/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import graphviz\n",
    "import os\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "from operator import itemgetter\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path_import = \"/Users/ppx/Desktop/\"\n",
    "#import_file = \"the_result_file.csv\"\n",
    "path = 'SMSSpamCollection.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GNB = GaussianNB()\n",
    "\n",
    "DTC = tree.DecisionTreeClassifier()\n",
    "\n",
    "ID3 = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "decision_stump = GradientBoostingClassifier(n_estimators=100,\n",
    "                                 learning_rate=1.0,\n",
    "                                 max_depth=1,\n",
    "                                 random_state=0)\n",
    "\n",
    "MLP = MLPClassifier(solver='lbfgs',\n",
    "                    alpha=1,\n",
    "                    hidden_layer_sizes=(20, 10))\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "BC = BaggingClassifier(n_estimators=50)\n",
    "\n",
    "ABC = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1.0,\n",
    "                         algorithm='SAMME.R',\n",
    "                         random_state=None)\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators=10,\n",
    "                             criterion='gini',\n",
    "                             max_depth=None,\n",
    "                             min_samples_split=2,\n",
    "                             min_samples_leaf=1,\n",
    "                             min_weight_fraction_leaf=0.0,\n",
    "                             max_features='auto',\n",
    "                             max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.0,\n",
    "                             min_impurity_split=None,\n",
    "                             bootstrap=True,\n",
    "                             oob_score=False,\n",
    "                             n_jobs=1,\n",
    "                             random_state=None,\n",
    "                             verbose=0,\n",
    "                             warm_start=False,\n",
    "                             class_weight=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_depth=7\n",
    "learning_rate=0.05\n",
    "n_estimators=50\n",
    "gamma=0.5\n",
    "reg_alpha=0.1\n",
    "\n",
    "\n",
    "GBM = xgb.XGBClassifier(max_depth = max_depth, \n",
    "                        n_estimators = n_estimators, \n",
    "                        learning_rate = learning_rate,\n",
    "                        gamma = gamma,\n",
    "                        reg_alpha= reg_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames = ['Accuracy', 'AUC', 'Moyenne CV', 'Std CV','precision', 'Temps']\n",
    "algos = [GNB, KNN, DTC, ID3, BC, RFC, ABC, decision_stump, GBM]\n",
    "indexs = ['GNB', 'KNN', 'DTC', 'id3', 'BC', 'RFC', 'ABC', 'DS','GBM']\n",
    "clfs = dict()\n",
    "for x in range(len(algos)):\n",
    "    clfs[indexs[x]] = algos[x]\n",
    "\n",
    "modes = [None, 'normalized', 'min_max_ed', 'pca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en forme donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(path, delimiter='\t',header=None, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mf = 500\n",
    "vectorizer = CountVectorizer(max_features=mf)\n",
    "X = vectorizer.fit_transform(data[1])\n",
    "analyze = vectorizer.build_analyzer()\n",
    "X = X.toarray()\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = pd.DataFrame(data[0])\n",
    "target = target.replace('spam', 1)\n",
    "target = target.replace('ham', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualité Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Qualite:\n",
    "    def __init__(self, _modele, _data, _y, _y_pred, _y_pred_proba, _cv=10, _print_mode=True):\n",
    "        \n",
    "        self.accuracy = sklearn.metrics.accuracy_score(_y, _y_pred)\n",
    "        self.AUC = sklearn.metrics.roc_auc_score(_y, _y_pred)\n",
    "        self.cross_validation = cross_val_score(_modele, _data, y=_y, cv=_cv)\n",
    "        self.moyenne = np.mean(self.cross_validation)\n",
    "        self.ecart_type = np.std(self.cross_validation)\n",
    "        self.precision = average_precision_score(_y, _y_pred)\n",
    "        \n",
    "        self.roc = ROC_curves(pred=_y_pred_proba, res=_y)\n",
    "        \n",
    "        \n",
    "        if _print_mode:\n",
    "            self.roc.plot_it()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TP(theta, pred, result):\n",
    "    count = 0\n",
    "    i = 0\n",
    "    for x in (result):\n",
    "        if pred[i][1] > theta and x == 1:\n",
    "            count += 1\n",
    "        i += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def FP(theta, pred, result):\n",
    "    count = 0\n",
    "    i = 0\n",
    "    for x in (result):\n",
    "        if pred[i][1] >= theta and x == 0:\n",
    "            count += 1\n",
    "        i += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def TN(theta, pred, result):\n",
    "    count = 0\n",
    "    i = 0\n",
    "    for x in (result):\n",
    "        if pred[i][1] < theta and x == 0:\n",
    "            count += 1\n",
    "        i += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def FN(theta, pred, result):\n",
    "    count = 0\n",
    "    i = 0\n",
    "    for x in (result):\n",
    "        if pred[i][1] < theta and x == 1:\n",
    "            count += 1\n",
    "        i += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "class ROC_curves:\n",
    "    def __init__(self, pred, res, gran = 101):\n",
    "        x = []\n",
    "        y = []\n",
    "        for j in range(0,gran):\n",
    "            tn = TN(j/(gran-1),pred,res)\n",
    "            neg = tn + FP(j/(gran-1),pred,res)\n",
    "            tp = TP(j/(gran-1),pred,res)\n",
    "            pos = tp + FN(j/(gran-1),pred,res)\n",
    "\n",
    "            if neg == 0:\n",
    "                x.append(0)\n",
    "            else:\n",
    "                x.append(tn / neg)\n",
    "            if pos == 0:\n",
    "                y.append(0)\n",
    "            else:\n",
    "                y.append(tp / pos)\n",
    "      \n",
    "        self.rocx = x\n",
    "        self.rocy = y\n",
    "    def plot_it(self):\n",
    "        plt.plot(self.rocx,self.rocy)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def algo_apprentissage(mod, data, target, print_mode=True, cv=10):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, \n",
    "                                                    target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "    result = dict()\n",
    "    mod_fit = mod.fit(X_train, y_train)\n",
    "    y_prediction_proba = mod_fit.predict_proba(X_test)\n",
    "    y_prediction = mod_fit.predict(X_test)\n",
    "    q_mod = Qualite(_modele=mod,\n",
    "                 _data=X_test,\n",
    "                 _y=y_test,\n",
    "                 _y_pred=y_prediction,\n",
    "                 _y_pred_proba=y_prediction_proba,\n",
    "                 _print_mode=print_mode,\n",
    "                 _cv=cv)\n",
    "    \n",
    "    result['y_prediction_proba'] = y_prediction_proba\n",
    "    result['y_prediction'] = y_prediction\n",
    "    result['q_mod'] = q_mod\n",
    "    \n",
    "    if print_mode:\n",
    "        print('La précision est ' + str(q_mod.accuracy))\n",
    "        print('')\n",
    "        print('L\\'AUC est ' + str(q_mod.AUC))\n",
    "        print('')\n",
    "        print('Le score moyen par ' + str(cv) + ' cross-validation est ' + str(q_mod.moyenne))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametres XGOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def param_XGB(data,\n",
    "              target,\n",
    "              max_depths=[10,50,100],\n",
    "              learning_rates=[0.1,0.01],\n",
    "              n_estimatorss=[50,100],\n",
    "              sound_alarm=True):\n",
    "    gamma=0.5\n",
    "    reg_alpha=0.1\n",
    "    colonnes = ['max_depth', 'learning_rates', 'n_estimators', 'score_moyen', 'qualite']\n",
    "    result = pd.DataFrame(columns=colonnes)\n",
    "    \n",
    "    for md in max_depths:\n",
    "        for lr in learning_rates:\n",
    "            for ne in n_estimatorss:\n",
    "                GBM = xgb.XGBClassifier(max_depth = md, \n",
    "                        n_estimators = ne, \n",
    "                        learning_rate = lr,\n",
    "                        gamma = gamma,\n",
    "                        reg_alpha= reg_alpha)\n",
    "                apprentissage = algo_apprentissage(mod=GBM, data=data, target=target, print_mode=False)\n",
    "                event = pd.DataFrame([[md, lr, ne, apprentissage['q_mod'].moyenne, apprentissage['q_mod']]], columns=colonnes)\n",
    "                result = result.append(event)\n",
    "                \n",
    "    if sound_alarm:\n",
    "        os.system('say \"done\"')\n",
    "        \n",
    "    result = result.reset_index()\n",
    "    return result\n",
    "\n",
    "# Attention, cette fonction mets du temps\n",
    "#table_param = param_XGB(data=X, target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_transform(data, target, variance=0.7, print_mode=True, normalized=True, min_max_ed=False):\n",
    "    if normalized:\n",
    "        scaler = StandardScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "    elif min_max_ed:\n",
    "        scaler = MinMaxScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "        \n",
    "        \n",
    "    for x in range(len(data[0])):\n",
    "        pca = PCA(n_components=x)\n",
    "        pca.fit(data)\n",
    "        if sum(pca.explained_variance_ratio_) > variance:## and x >1:\n",
    "            if print_mode:\n",
    "                print('Hello World')\n",
    "            break\n",
    "    X_pca = pca.fit_transform(data)\n",
    "    if print_mode:\n",
    "        plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    return [pca, X_pca]\n",
    "        \n",
    "        \n",
    "#pca_data = pca_transform(data=data['cleaned_data'], target=data['target'], normalized=True, print_mode=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cvalidation=None,\n",
    "                        n_jobs=4, train_sizes=np.linspace(.1, 1.0, 5), print_mode=True):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cvalidation : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cvalidation, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    if print_mode:\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    return plt\n",
    "\n",
    "\n",
    "title = \"Learning Curves\"\n",
    "cvalidation = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "estimator = KNN\n",
    "# plot_learning_curve(estimator, title, X=data['cleaned_data'], y=data['target'], ylim=(0.4, 1.01), cvalidation=cvalidation, n_jobs=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_table(data,\n",
    "                target,\n",
    "                col=colnames,\n",
    "                algos=algos,\n",
    "                indexs=indexs,\n",
    "                mode=None,\n",
    "               print_mode=True):\n",
    "    if mode is None:\n",
    "        pass\n",
    "    elif mode == 'normalized':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(data)\n",
    "        data = scaler.transform(data)\n",
    "    elif mode == 'min_max_ed':\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(data)\n",
    "        data = scaler.transform(data)\n",
    "    elif mode == 'pca':\n",
    "        data = pca_transform(data=data,\n",
    "                             target=target,\n",
    "                                 normalized=True,\n",
    "                                 print_mode=False)[1]\n",
    "\n",
    "\n",
    "    result = []\n",
    "    for alg in algos:\n",
    "        t1 = time.time()\n",
    "        res_algo = algo_apprentissage(alg, data=data, target=target, print_mode=print_mode)\n",
    "        t2 = time.time()\n",
    "        delta_t = t2 - t1\n",
    "        ajout = [res_algo['q_mod'].accuracy, \n",
    "                 res_algo['q_mod'].AUC, \n",
    "                 res_algo['q_mod'].moyenne, \n",
    "                 res_algo['q_mod'].ecart_type, \n",
    "                 res_algo['q_mod'].precision,\n",
    "                 delta_t]\n",
    "        result.append(ajout)\n",
    "        if print_mode:\n",
    "            cvalidation = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "            plot_learning_curve(alg, 'str(alg)', X=data, y=target, ylim=(0.4, 1.01), cvalidation=cvalidation, n_jobs=4)\n",
    "\n",
    "\n",
    "\n",
    "    result = pd.DataFrame(result, columns=colnames, index=indexs)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comparisons_tables(data, target, modes=modes, print_mode=True):\n",
    "    tables = dict()\n",
    "    for mode in modes:\n",
    "        event = dict()\n",
    "        tables[str(mode)] = final_table(data=data, target=target, mode=mode, print_mode=print_mode)\n",
    "    \n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bis = target.values.reshape(5572,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention, cela prend beaucoup de temps\n",
    "final = final_table(X, target_bis, print_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Moyenne CV</th>\n",
       "      <th>Std CV</th>\n",
       "      <th>precision</th>\n",
       "      <th>Temps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GNB</th>\n",
       "      <td>0.684305</td>\n",
       "      <td>0.800777</td>\n",
       "      <td>0.844882</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>0.286039</td>\n",
       "      <td>0.425154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.938117</td>\n",
       "      <td>0.771294</td>\n",
       "      <td>0.892381</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.597981</td>\n",
       "      <td>10.135946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC</th>\n",
       "      <td>0.970404</td>\n",
       "      <td>0.931833</td>\n",
       "      <td>0.957866</td>\n",
       "      <td>0.016950</td>\n",
       "      <td>0.805010</td>\n",
       "      <td>1.697799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.936742</td>\n",
       "      <td>0.956949</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.827327</td>\n",
       "      <td>1.152536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.941383</td>\n",
       "      <td>0.960561</td>\n",
       "      <td>0.017454</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>19.096726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>0.981166</td>\n",
       "      <td>0.929530</td>\n",
       "      <td>0.965950</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.877894</td>\n",
       "      <td>0.722763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABC</th>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.928228</td>\n",
       "      <td>0.956990</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.827246</td>\n",
       "      <td>3.583408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DS</th>\n",
       "      <td>0.919283</td>\n",
       "      <td>0.820025</td>\n",
       "      <td>0.920221</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.523708</td>\n",
       "      <td>5.111948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBM</th>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.916875</td>\n",
       "      <td>0.959692</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.828184</td>\n",
       "      <td>15.044076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy       AUC  Moyenne CV    Std CV  precision      Temps\n",
       "GNB  0.684305  0.800777    0.844882  0.020545   0.286039   0.425154\n",
       "KNN  0.938117  0.771294    0.892381  0.014901   0.597981  10.135946\n",
       "DTC  0.970404  0.931833    0.957866  0.016950   0.805010   1.697799\n",
       "id3  0.973991  0.936742    0.956949  0.012614   0.827327   1.152536\n",
       "BC   0.972197  0.941383    0.960561  0.017454   0.816853  19.096726\n",
       "RFC  0.981166  0.929530    0.965950  0.012456   0.877894   0.722763\n",
       "ABC  0.973991  0.928228    0.956990  0.014833   0.827246   3.583408\n",
       "DS   0.919283  0.820025    0.920221  0.021997   0.523708   5.111948\n",
       "GBM  0.973991  0.916875    0.959692  0.016016   0.828184  15.044076"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _cs_matrix.toarray of <5572x500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50729 stored elements in Compressed Sparse Row format>>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tfidf = pd.DataFrame(transformer.fit_transform(X).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544836</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.310483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.324723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.136927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478425</td>\n",
       "      <td>0.137987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327418</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163861</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395411</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297373</td>\n",
       "      <td>0.107210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306348</td>\n",
       "      <td>0.220892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156175</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1         2    3         4    5         6    7    8    9    \\\n",
       "0     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "1     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "2     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "3     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "4     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "6     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "7     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "8     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "9     0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "10    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "11    0.310483  0.0  0.290480  0.0  0.263889  0.0  0.277177  0.0  0.0  0.0   \n",
       "12    0.324723  0.0  0.303802  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "13    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "14    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "15    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "16    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "17    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "18    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "19    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.423812  0.0  0.0  0.0   \n",
       "20    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "21    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "22    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "23    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "24    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "25    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "26    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "27    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "28    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "29    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "...        ...  ...       ...  ...       ...  ...       ...  ...  ...  ...   \n",
       "5542  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5543  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5544  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5545  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5546  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5547  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5548  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5549  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5550  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5551  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5552  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5553  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5554  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5555  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5556  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5557  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5558  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5559  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5560  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5561  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5562  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5563  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5564  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5565  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5566  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5567  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5568  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5569  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5570  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "5571  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "     ...   490  491  492       493  494  495  496       497       498  499  \n",
       "0    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "1    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "2    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "3    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "4    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.103459  0.000000  0.0  \n",
       "6    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "7    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.544836  0.0  \n",
       "8    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.109930  0.000000  0.0  \n",
       "9    ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.131269  0.0  \n",
       "10   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "11   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "12   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.116244  0.000000  0.0  \n",
       "13   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.189900  0.136927  0.0  \n",
       "14   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "15   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.215390  0.0  \n",
       "16   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "17   ...   0.0  0.0  0.0  0.315506  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "18   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "19   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "20   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.220749  0.000000  0.0  \n",
       "21   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "22   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "23   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "24   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.180619  0.000000  0.0  \n",
       "25   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "26   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.358491  0.0  \n",
       "27   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.478425  0.137987  0.0  \n",
       "28   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.135227  0.000000  0.0  \n",
       "29   ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "...  ...   ...  ...  ...       ...  ...  ...  ...       ...       ...  ...  \n",
       "5542 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.327418  0.0  \n",
       "5543 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5544 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.228317  0.000000  0.0  \n",
       "5545 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.189589  0.000000  0.0  \n",
       "5546 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5547 ...   0.0  0.0  0.0  0.251231  0.0  0.0  0.0  0.000000  0.163861  0.0  \n",
       "5548 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5549 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.144770  0.000000  0.0  \n",
       "5550 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.354836  0.000000  0.0  \n",
       "5551 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.190109  0.000000  0.0  \n",
       "5552 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.183671  0.000000  0.0  \n",
       "5553 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.395411  0.0  \n",
       "5554 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5555 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5556 ...   0.0  0.0  0.0  0.353282  0.0  0.0  0.0  0.159782  0.000000  0.0  \n",
       "5557 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.297373  0.107210  0.0  \n",
       "5558 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5559 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.173196  0.000000  0.0  \n",
       "5560 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5561 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5562 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5563 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5564 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.306348  0.220892  0.0  \n",
       "5565 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5566 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.156175  0.0  \n",
       "5567 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5568 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5569 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5570 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "5571 ...   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0  \n",
       "\n",
       "[5572 rows x 500 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a14ae42b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La précision est 0.745291479821\n",
      "\n",
      "L'AUC est 0.827459113205\n",
      "\n",
      "Le score moyen par 10 cross-validation est 0.842186878437\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl8lOW9///XNfskM1nZZA27JCA7ooiAiHVHEI5btbUq\n2kp7rL+q9Oix6rd6aOtR3Opat0pFQajWolYsUD1WETSoBFD2TbaQPZNkluv3xzVzZ5JMNshAhM/z\n8ZhHZu65554rEec916601gghhBAAtmNdACGEEO2HhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQ\nQgiLhIIQh0kpdaNSal4Lz31RKfXbFp77v0qpnx5Z6YQ4PBIKQsRRSt2jlHqlBee5gLuAPyShGA8C\n/xV9DyGOKgkFIVpBGTZgKrBBa727rd9Da/0dsAG4uK2vLURzJBTECUspdYdSardSqkwptVEpdQHw\nX8BlSqlypdTa6HkrlFL3K6X+D6gE+gDnASvrXW+hUmqvUqpEKfUvpVReE+99u1LqO6XUHqXU9Uop\nrZTqF3fKCuCCNv6VhWiWhII4ISmlBgKzgdFaaz/wA8y38weA17TWPq310LiXXA3MAvzAdmAIsLHe\nZd8B+gOdgM+B+Y2897nArcDZQD9gYoLT1gNDExwXIqkkFMSJKgy4gVyllFNrvU1rvbmJ81/UWq/T\nWoe01kEgAyiLP0Fr/bzWukxrXQ3cAwxVSqUnuNZ/AC9Er1cZPbe+suh7CHFUSSiIE5LWehNwC+YD\neb9SaoFSqmsTL9lZ73ERptYAgFLKrpSaq5TarJQqBbZFn+qQ4Fpd612v/rWJXru4yV9CiCSQUBAn\nLK31X7TWZwC9AA38Lvoz4en1Hn8JDIh7fCWm8/lsIB3IiR5XCa71HdA97nGPBOcMAtY2UXwhkkJC\nQZyQlFIDlVJnKaXcQBUQACLAPiAnOsKoKUuBCXGP/UA1UAikYPomGvM6cK1SapBSKgX47wTnTMD0\nUQhxVEkoiBOVG5gLHAT2YjqHfw0sjD5fqJT6vInX/w04Oa7J6WVMB/RuoAD4pLEXaq3fAR4FlgOb\n4s6tBlBKnQTkAn9t9W8lxBFSssmOEIdHKTULyNVa33KE1xkEfA24tdYhpdT/Apu11n9si3IK0RoS\nCkIcA0qpaZgmqBTgJSCitb7k2JZKCGk+EuJYuRHYD2zGDI+VtY5EuyA1BSGEEBapKQghhLA4jnUB\nWqtDhw46Jyenza5XUVFBampqm12vrbTHcrXHMoGUq7WkXK1zvJRrzZo1B7XWHZs9UWudlBvwPKbN\n9OtGnleYYXmbMBOBRrTkuiNHjtRtafny5W16vbbSHsvVHsuktZSrtaRcrXO8lAtYrVvwGZvM5qMX\ngXObeP48zOJh/TELjT2ZxLIIIYRogaSFgtb6X8ChJk6ZCrwcDbFPgIzopB0hhBDHSFJHHymlcoC3\ntdaDEzz3NjBXa/1R9PEHwB1a69UJzp2FqU3QuXPnkQsWLGizMpaXl+Pz+drsem2lPZarPZYJpFyt\nJeVqneOlXJMmTVqjtR7V3Hnfi45mrfUzwDMAo0aN0hMnTmyza69YsYK2vF5baY/lao9lguOnXMFg\nkF27dlFVVZW8QgHp6el4PJ6kvsfhkHK1TmPl8ng8dO/eHafTeVjXPZahsJu6q0N2jx4T4oS0a9cu\n/H4/OTk5KJVocdW2UVZWht/vb/7Eo0zK1TqJyqW1prCwkF27dtG7d+/Duu6xnKfwFnBNdM/bsUCJ\nNnvTCnFCqqqqIjs7O6mBII5vSimys7OPqLaZtJqCUupVzDaDHZRSu4DfAE4ArfVTmHVfzscMSa0E\nrk1WWYT4vpBAEEfqSP8NJS0UtNZXNPO8Bm5O1vsLIYRoPVnmQggBQGFhIcOGDWPYsGF06dKFbt26\nWY9rampadI1rr72WjRs3NnnOE088wfz589uiyCIJvhejj4QQCcyfD3feCTt2QM+ecP/9cNVVh325\n7Oxs8vPzAbjnnnvw+Xz86le/qnOONevVlvj75AsvvNDs+9x8c/tsIGjudztRnNi/vRDfV/Pnw6xZ\nsH07aG1+zppljrexTZs2kZuby1VXXUVeXh7fffcds2bNYtSoUeTl5XHfffdZ555xxhnk5+cTCoXI\nyMhgzpw5DB06lNNOO439+/cDcNdddzFv3jzr/Dlz5jBmzBhGjBjBxx9/DJh1fS699FJyc3OZMWMG\no0aNsgIr3m233UZubi6nnHIKd9xxBwB79+5l6tSpnHLKKQwdOpRPP/0UgN///vcMHjyYwYMH89hj\njzX6u73zzjucdtppjBgxgssuu4yKioo2/5u2Z1JTEKI9uuUWSPAhaPnkE6iurnusshKuuw6efTbx\na4YNg+iHcWtt2LCBl19+mVGjzNynuXPnkpWVRSgUYtKkScyYMYPc3Nw6rykpKWHChAnMnTuXW2+9\nleeff545c+Y0uLbWmlWrVvHaa69x33338e677/LYY4/RpUsX3njjDdauXcuIESMavG7fvn0sXbqU\ndevWoZSiuLgYMDWRKVOmMHv2bEKhEJWVlXz66afMnz+fzz77jFAoxJgxY5g4cSJer7fO77Z//37m\nzp3LBx98QEpKCvfffz9PPvkk995772H93b6PpKYgxPdR/UBo7vgR6tu3rxUIAK+++iojRoxgxIgR\nrF+/noKCggav8Xq9nHfeeQCMHDmSbdu2Jbz29OnTARg2bJh1zkcffcTll18OwNChQ8nLy2vwuqys\nLGw2GzfccANLliyxVgxdsWIFN954IwAOh4O0tDQ++ugjLr30UrxeL36/n0suuYQPP/ywwe/28ccf\nU1BQwOmnn86wYcOYP38+O3bsaO2f63tNagpCtEfNfaPPyTFNRvX16gUrVrR5ceKXaP7222955JFH\nWLVqFRkZGfzwhz9MOC7e5XJZ9+12O6FQKOG13W53s+ck4nQ6Wb16Ne+//z4LFy7kySef5B//+AfQ\numGZ8b+b1ppzzz2XP//5z9axsrKyFl/reCA1BSG+j+6/H1JS6h5LSTHHk6y0tBS/309aWhrfffcd\n7733Xpu/x7hx43j99dcB+OqrrxLWRMrKyigtLeXCCy/k4Ycf5osvvgBg0qRJPPXUUwCEw2FKS0sZ\nP348S5YsIRAIUF5ezptvvsn48eMbXPP0009n5cqVbNmyBTB9G5s2bWrz3689k5qCEN9HsVFGbTj6\nqKVGjBhBbm4uJ598Mr169WLcuHFt/h4///nPueaaa8jNzbVu6enpdc4pKSlh+vTpVFdXE4lEeOih\nhwB4/PHHueGGG3j66adxOBw8/fTTjBkzhiuuuILRo0cD8NOf/pQhQ4Y0+MDv3Lkzf/rTn7jsssus\nYbh33XUXw4cPb/Pfsd1qyaYL7ekmm+wcO+2xTFofP+UqKChITkHqKS0tPSrv01rx5QoGgzoQCGit\ntf7mm290Tk6ODgaDx7xc7UlT5Ur0b4kWbrIjNQUhRLtTXl7O5MmTCYVCaK2tb/0i+eSvLIRodzIy\nMlizZs2xLsYJSTqahRBCWCQUhBBCWCQUhBBCWCQUhBBCWE6sUAgGoYVLAAtxItq7dy+XX345ffv2\nZeTIkZx//vl88803x7pYCeXk5HDw4EHATDpL5Mc//jGLFi1q8jovvvgie/bssR5ff/31CSfLnShO\nrFAoL4dNm2DPHkjy5uhCJNv8r+aTMy8H2702cublMP+rI1shVWvNtGnTmDhxIps3b2bNmjX8z//8\nD/v27atzXmuWojhaYqurHo76ofDcc881WNyvPThaf/cTKxQAXC4IBMy6Mbt2mWWHhfiemf/VfGb9\nbRbbS7aj0Wwv2c6sv806omBYvnw5TqeTm266yTo2dOhQxo8fz4oVKxg/fjwXX3yx9YH50EMPWUtR\nx5bCrqio4IILLmDo0KEMHjyY1157DYA5c+ZYS1zX36MB4KmnnuKuu+6yHr/44ovMnj0bgEsuuYSR\nI0eSl5fHM888k7DsPp8PMME2e/ZsBg4cyNlnn20t1w1w3333MXr0aAYPHsysWbPQWrNo0SJWr17N\nVVddxbBhwwgEAkycOJHVq1cDZuG/sWPHMnjwYGtp7tj73XnnnQwdOpSxY8c2CE6AlStXWpsUDR8+\n3FpD6Xe/+x1Dhgxh6NCh1qqx+fn5jB07llNOOYVp06ZRVFQEwMSJE7nlllsYNWoUjzzyCAcOHODS\nSy9l9OjRTJgwgf/7v/9r/D/oYTox5yl4veZnVZVpTtqxAzp0MMdlj1zRDtzy7i3k72186exPdn1C\ndbjuiqiVwUque/M6nl2TeOnsYV2GMe/cxhfa+/rrrxk5cmSjz3/++ed8/fXX9O7dmzVr1vDCCy/w\n6aeforXm1FNPZcKECWzZsoWuXbvy97//HTBLURQWFrJkyRI2bNhQZ4nreJdeeimnnnoqjzzyCACv\nvfYad955JwDPP/88WVlZBAIBRo8ezaWXXkp2dnbCMi5ZsoSNGzdSUFDAvn37yM3N5Sc/+QkAs2fP\n5u677wbg6quv5u2332bGjBk8/vjjPPjgg3VWgQXYs2cPd9xxBytXrqRHjx6cc845/PWvf+WSSy6h\noqKCsWPHcv/993P77bfz7LPP1gk1gAcffJAnnniCcePGUV5ejsfj4Z133uHNN9/k008/JSUlhUOH\nDgFwzTXX8NhjjzFhwgTuvvtu7r33Xitoa2pqrJC68sor+eUvf8kZZ5xBQUEBl156KevXr2/0v9nh\nODFqCvPnm1Uls7NhwgRYvNgc93jAZoNIxATD9u1QUSG1B9Hu1Q+E5o63hTFjxtC7d2/ALG09bdo0\nUlNT8fl8TJ8+nQ8//JAhQ4bw/vvvc8cdd/Dhhx+Snp5Oeno6Ho+H6667jsWLF5NSfyE/oGPHjuTk\n5PDJJ59QWFjIhg0brDWVHn30Uesb+c6dO/n2228bLeO//vUvrrjiCux2O127duWss86ynlu+fDmn\nnnoqQ4YM4Z///Cfr1q1r8vf97LPPmDhxIh06dMDhcHDVVVfxr3/9CzArwF544YVA48uCjxs3jltv\nvZVHH32U4uJiHA4Hy5Yt49prr7X+BllZWZSUlFBcXMyECRMA+NGPfmS9D8Bll11m3V+2bBmzZ89m\n2LBhXH755ZSWllJeXt7k79Fax39NIbZDVWWlebxnD9x+u7kfXccdl8vcgkHTpOR0mpqDz2dCQ4ij\nrKlv9AA583LYXtJw6exe6b1Y8eMVh/WeeXl5TXbKxi8x3ZgBAwbw+eefs3TpUu666y4mT57M3Xff\nzapVq/jggw9YtGgRjz/+OO+//75VK7n44ou57777mDFjBq+//jonn3wy06ZNQynFihUrWLZsGf/+\n979JSUlh4sSJCZfpbk5VVRU/+9nPWL16NT169OCee+45rOvEOJ1Oa3nuxpb8njNnDhdccAFLly5l\n3Lhxh72abPzfPRKJ8Mknn+DxeCgrK8Pv9x/eL9CE4/8T7847awMhJhCAuXMbnut0gt8PDgfs3Qtb\nt0JJialJCNGO3D/5flKcdb9xpzhTuH/y4S+dfdZZZ1FdXV2n3f7LL7+0NqOJN378eP76179SWVlJ\nRUUFS5YsYfz48ezZs4eUlBR++MMfctttt/H5559TXl5OSUkJ559/Pg8//DBr167FbreTn59Pfn6+\ntZ3nhRdeyJtvvsmrr75qbbBTUlJCZmYmKSkpbNiwgU8++aTJ3+HMM8/ktddeIxwO891337F8+XIA\nKwA6dOhAeXl5nfDz+/0J90wYM2YMK1eupLCwkHA4zKuvvmp9m2+JzZs3M2TIEO644w5Gjx7Nhg0b\nmDJlCi+88AKV0c+kQ4cOkZ6eTmZmpvV3/vOf/9zo+5xzzjnWVqJAwi1Kj9TxX1NobNekuNEGDTgc\nppYQDsO+fXDggGl6SksDuz055RSiFa4aYpbIvvODO9lRsoOe6T25f/L91vHDoZRiyZIl3HLLLfzu\nd7/D4/GQk5PDvHnz2L17d51zR4wYwY9//GPGjBkDmGGcw4cP57333uO2227DZrPhdDp58sknKSsr\nY+rUqVRVVaG1tpa4ri8zM5NBgwZRUFBgXffcc8/lqaeeYtCgQQwcOJCxY8c2+TtMmzaNf/7zn+Tm\n5tKzZ09OO+00wKyldMMNNzB48GC6dOliLaENZtjqTTfdhNfr5d///rd1/KSTTmLu3LlccMEFKKW4\n4IILmDp1aov/nvPmzWP58uXYbDby8vI477zzcLvd5OfnM2rUKFwuF+effz4PPPAAL730EjfddBOV\nlZX06dOHF154IeE1H330UW6++WZOOeUUampqmDhxorV3RFtR+nvWfj5q1Cgd63RpkcZ2qAI46yy+\nOP98hl9+edMdzJGIqW0oVRsOSV6xccWKFUycODGp79Fa7bFMcPyUa/369QwaNCh5BYpKVrPDkZJy\ntU5T5Ur0b0kptUZrPSrhC+Ic/81HiXao8njgwgth7VqG/+pXcPHF8N57jTcT2Wym5uD1QmEhbNkC\nBw+aPgghhDiOHP+hcNVV8MwzZu9apaBrV/jDH+Dpp+HTT/lm9mzTPPSTn8BZZ8FrrzU+69lmg9RU\ncysqMuGwb5/MkhZCHDeSGgpKqXOVUhuVUpuUUnMSPJ+plFqilPpSKbVKKTU4KQW56irYts18y1+5\nsnbUkdfLnosvho8+gieeME1Ct94Kp59ugqSiorFfzASDz2dmSW/dCt99B9XJGw4oTgzft+Zc0f4c\n6b+hpIWCUsoOPAGcB+QCVyil6s8d/y8gX2t9CnAN8EiyytMkhwMuuQTefx9eecX0Q9x7L4wZY2oV\nhYWJX6eUaVLy+02fw9atZkhrIHBUiy+ODx6Ph8LCQgkGcdi01hQWFuLxeA77GsnsLR0DbNJabwFQ\nSi0ApgLxK03lAnMBtNYblFI5SqnOWuuGc8aPBqVg0iRzW7MG/vhHmDcPnnoKrrgCbrwRevRI/Fqv\n19yqqsyIJ69XZkmLVunevTu7du3iwIEDSX2fqqqqI/rQSBYpV+s0Vi6Px0P37t0P+7rJDIVuwM64\nx7uAU+udsxaYDnyolBoD9AK6A8kJBYfDDDOtrGz+w3rkSPjTn+Dbb+HJJ00N4uWXYepU+OlPobEF\nszwec6uuhp07we2Gjh1NZ7eEg2iC0+m0Zgwn04oVKxg+fHjS36e1pFytk6xyJW1IqlJqBnCu1vr6\n6OOrgVO11rPjzknDNBkNB74CTgZu0Frn17vWLGAWQOfOnUcuWLDg8AumtQmGcBiA8poafC34FuA+\ncIDuixdz0tKlOAIBCseMYcd//AclQ4Y0/WGvtbkpZUKphTOky8vLrUW+2ov2WCaQcrWWlKt1jpdy\nTZo0qUVDUpMZCqcB92itfxB9/GsArfX/NHK+ArYCp2itSxu7bqvnKTQmFIKyMlasWsXEnBxTc2jJ\n3IOiInjpJXj+edPXMHIk3HwzTJnS9Ad+KGT6GhwO06zk9zd5fnsce98eywRSrtaScrXO8VKu9jBP\n4TOgv1Kqt1LKBVwOvBV/glIqI/ocwPXAv5oKhCMVDAepCplZlTgckJlpmndOOskKiWaHl2Zmwi23\nwKefmjkQ+/e3bDirw2GCwOUyw1i3bDEBE62xCCFEe5C0UNBah4DZwHvAeuB1rfU6pdRNSqnYgu2D\ngK+VUhsxo5T+M1nlASivKWdL0Ra2Fm3lUOAQ1aHoENK0NOjdG7p3N9/ey8qa34TH64Uf/7j1w1nt\ndjOU1e028yO2bIFDh0woCSHEMZbUtRq01kuBpfWOPRV3/9/AgGSWoT6X3YXT7qSwspAD+gA14RpK\nqkpIcabgjE1MCwTMt/iyMvMh3lSndGw469SpsHy5GbF0773wyCMmNH7yE7M0Rn2xcIhETDPUwYOQ\nlQXp6WZhPiGEOAaO/xnN1G5bmP37bCa8OIE3N75JqisVv9usG7K/Yj9bi7ayo2QHpVWlhNxOM/O5\nd29TiygvN9/8m1otVSnThLRoEbz1Fowda4azjhkDd91lRiIl0tgsaRmrLoQ4Bo77UKi/beGesj3c\n/v7tLF5vNtpRSpHqSsXn9hHREfZW7GXzoc3sKtlFOTWEO2RD377m234gYAKiuX6A2HDWFStMDeKV\nV2DcOPj5z6GxDcHrz5KurpZZ0kKIo+64D4U7P7iTymDd/RQCoQAPfPhAg3Nddhc+lw+/208wEmRP\n6R62FG1hb+AglX4Pkd450LmzWQivrKz5BfH694eHHoKPP4brroN33zWjlK6+2nRUJ6oNxGZJ2+0y\nS1oIcdQd96GwoyTxfgrflX/H1YuvZsWBFVSFGnYqux1ufG4fKc4UKoIV7CzZyeaSbex3VFPV4yR0\n167mQ70lndJdu8JvfgOrVsFtt8HatWb9palTm16d1es1zVexfaR37DBBIU1LQogkOe5DoWd6z4TH\n/S4/6w+u54ENDzD86eHc/v7tfLbnswbrziil8Dq9+N1+vE4vZdVlbC/ZwZbgfgo7+qju2tkMMy0t\nNd/mm/rAPtzhrB6PGc4aDpu+CdlLWgiRJMd9KCTattDr8PLA5Af49PpP+d3g3zGlzxQWr1/MJQsu\n4YwXzuDhTx5mV+muBteyKZsVEC67i0NVRWyr3seW1BqKTsqgxuM0/QGVlU13SscPZ3388ZYPZ3W7\nTTiAaVLautXUVGS7UCFEGznuQ+GqIVfxzEXP0Cu9FwpFV39Xfj/l90wfNB27zc7wzOE8et6j5N+U\nz0M/eIiTfCfx4McPcupzpzLj9Rm8tu41KmoafkjbbXZrBJPD5uBgqIyt7gA7sp2Ueu2EKsqa75R2\nOGDaNLM665//XGd11pyXXmp8dVaXq3Yv6T17zLLgspe0EKINHP97NGOC4aohV1EUKOJg5UFSXakN\nzvG5fFyWdxmX5V3GzpKdLFq/iEXrFnHre7dy5wd3cn7/85mZN5NxPcZhU3Wz1GFz4HCZP2UwHGSv\nqkY7NanVQTIqqvBqB/aU1MbnH8SGs551lrU6a878+fDGG02vzhqbJS17SQsh2sgJEQoxXqcXh81B\nWXUZDpsDjyPxQng90nvwy7G/5JZTb2H1ntUsLFjIWxvf4o31b9DV35VLB13KzLyZ9M3s2+C1TrsT\np918+Fc7q9ntrkIFAvjLS0nXbjwpadg83sYLGR3OuuqddxgT298htjrrz34GifbwjU2EC4dNMBw8\neNT2khZCHF+O++ajeB6Hh96ZvemV0Qu/209lsJJIJEJNOHEHr1KK0d1G8/spv+eLG7/gj+f/kYHZ\nA3nisyc484UzuejVi3h57csUVxUnfL3b4cbvTSc1szOBkzqyM12xuWIX+/dvI1BW1ORmKpU9ezYc\nznr22U0PZ42Fg+wlLYQ4TCdUKMR4HB46pXaib1ZfnHYnNmWjrLqMipoKIjpxu7zX6WXqyVN5Zfor\nfHbDZ9w1/i4qair49Qe/ZsTTI7jx7RtZtmUZoUjDNYyUUnicXvwZnfD26ktZp3R2RIrY8t06Cg/t\npjrBkFhL/eGs+fm1w1n/8Y/E/Qj1Z0lv3WpGOsle0kKIZpzQbQs2ZcOmbPRM70lNuIay6jKKAkWE\ndRiX3YXb4U74ui6+Lvx09E+5adRNfL3/axYWLGTJhiW8/c3bdEzpyLRB05iZO5Pcjg034rEpG15/\nJvgzCVcFKCoppHD/tzhsDjLTO5Pq8uGyuxq+aWw46403muGrTz0F114LAwaYTX8uucR0QMeLzZLW\n2gyZPXTIrK2UlWVGMgkhRD0nZE0hEZfdRXZKNn2y+tA9rTtOm9OqPYQjiUcQKaUY0nkI9026jzWz\n1vD8xc8zqusoXvjiBab8eQpT/jyFZ9Y8w8HKgwlfb/d4SencHV/fQTiyO3Kw5Du27l3PtqJtRHQk\nYa2jwXBWux1++UsznPXZZxMPZ1XK7PyWllY7S3r37uYn3QkhTjgSCvXYlI1UVyrd07vTJ7MPHVI6\nEAwHKasuIxAMNNoP4LK7+EG/H/Dcxc/x+Y2f89tJv8Vpc3LvynsZ8fQIfvTXH/H2N2/XLtcdz+HA\nkdWB1L6D8HfrgwqHCYaq2VK4mV3leygPJgim+sNZe/WCe+4xC/D94Q+ND2eNzZKurjaT4GSWtBAi\nzgndfNQcp91JpjeTDE8GVaEqSqpKKKkuQaHwOD04bIn/fFneLK4dfi3XDr+WjQc3sqhgEYvXL2bZ\nlmVkuDO4+OSLmZk7k+FdhqPil+S22cDvx+nzYdv/NT63j+qyYnZXFKM8bnyOVDLc6Xjs7tphsfHD\nWVevNkt3z5tnmpeuvNI0NyXaxFv2khZCJCA1hRaILXXRxd+Fvll96ezrTDgSbrb2ADCww0DuPPNO\nVt2wivnT5zMxZyKvf/06F716ERNfmshjqx5jT9me+m9oAqJbN9w9++D3ZZFaFaGqvJidZbvNGkyB\ngwRC9d571CizTeiKFXDxxWYo6+mnm9VZ169PXECZJS2EiCOh0EoOm4N0T3qDoa1l1WWNDm0FMwN6\nYs5EnrjgCb646Qv+MOUPZHmzmPvRXMY8O4bLF13OGwVvNFjRFY8HunRB9eyFJ6MD/iCk1GjKqkrZ\nUb6HLaXbORgopDpcXRsQ/fvDww+b4aw/+UnLhrMmmiVdWirbhQpxgpHmoyPgcXjwODxke7OpDFZS\nVFVEaVUpDruZGFd/5nNMmjuNK4dcyZVDrmRb8TYWFSxiUcEifvHuL0j9IJULB1zIaNtoBulBtddw\nuaBDB8jIQJWV4S0uhogm4rFTXFNKYXUxTuUg05NOqiPFjGDq1s30M/znf8JLL5k9HqZPNxPkZs82\nQWGrV8bYLOlQCPburX3v2C5xoZBMiBPiOCY1hTZgt9nxu/30TO9J78zeZLgzqApWUVZdlrhjOU5O\nRg6/Ov1XfHzdxyyauYgLB1zI29+8za+++hWn/+l0Hvz4QbYVb6t9gcNhhqf27AkdO2ILRUipDuNX\nbhw2OwerDrG1dAfbynZSUl1qRjDFhrOuWgW//a2Zs3DttTB5Mrz+euL5Cw6HCQKfzwRHSYmZBLd5\ns5kUt3+/GekkE+OEOK5IKLQxt8NNh9QOrRraCmbU02k9TuOhHzxE/k353D7wdnIycpj3yTzGPT+O\naa9N4y8XKj6jAAAgAElEQVRf/YXS6lLzArvdjCLq2RNOMns7OCqrSA3b8bt8KGBf1QE2l26rHcHk\ndpkwaM1wVjAB4fVaHeE4nabfYfduExCbN5taRXm5CRgZySTE95aEQpI0NbS1KlTVZOd0ijOFszud\nzYIZC1h1wyp+fcavORQ4xG3v38bwp4Zz899vZsW2FSZkYnMQunc3zUVOs3y3syaMz56C3+kjFAmz\nu2Ivm8u2sadiLxW6hsglUxMPZ33wQTPJbfFi87h7d/Nz8eLaAtrtJiR8PhMSbrcZ1rpnj+mo3rzZ\n3C8tNaObJCSE+N6QxuGjIH5oayAUoLiqmLLqsmaHtgJ09Xdl9pjZ3Dz6ZvL35rOwYCFvbniTv278\nK51TOzN90HRm5s5kYIeB5oPa6zUfxCUl5tu8zYbL7cblTEVrTVW4mrLy71AKMtzp+M88Dc+kSajo\n6qw8/DA89pj5II91Mu/eDbffTqdf/ALy8hoW0mYzHeIxWpsyVFSYfohYcMUCxOVq2JchhGgXJBSO\nIqUUKc4UUpwphFJDVNRUUBgoJBAMWKu2qkbmCCilGH7ScIafNJzfTPgNy7YsY2HBQp5Z8wxPrn6S\nUzqfwszcmVxy8iVkebOgUyfTl1BWBsXFoDXK68Fjd+Oxu9FaU1ZTTlF1CQ5lJz2vN75n/oh783bU\nhReab/7xAgH6PvecGd7a3DwGpcyHf2wpDa1N38P+/bVDXWM1Da/XhIQs9S1EuyChcIzEhramudOo\nDldTWl1KSVUJGo3b3vS6RG6HmwsGXMAFAy7gYOVBlmxYwsJ1C/nv5f/NfSvvY3LvyczMm8lZvc/C\nlZVl1juqqDDNQuEAuD0ohwNvdOnwiI7UjmDq4qF3IECij313YSEMGWJGL40caeZFDBtmagFNUcp8\n8MevzRQMRssTrY243SYkUlLMeTLCSYhjQv7PO8aUUnWGtlbUVHAocIhIJEJlsLLJoa0AHVI6cMOI\nG7hhxA0UHCgwi/OtX8K7m98ly5vFJQMvYWbeTIZ0GoLy+UwN4NAh0ykc/aC2KRspDrPHQzgSJtSl\nE87v9jV4r6Dfj/Occ8xGQMuWmYN2u9njYdSo2rDo2bP52oTTWXfToVDINHnFludwOk1IpKaacja2\nQZEQok1JKLQjdpudNE8aaZ40tjq2kuHOoLiquNlVW2NyO+bymwm/4c7xd7Ji2woWFizkla9e4fn8\n5xmYPZCZuTOZPmg6nXv0MIvhFR2CinKwO6w+AbvNTvn/93PS7/ottrgF8yIeNwU3zaLDDVeQ4vDi\nLgvgyv8Kx+f5JiQWLoQXXzQnd+xYtzYxZIhpJmqKw1G3dhAO12n6wuEwAeHz1YaELMchRJuTUGin\nFIoOqR3ISskiEAxQFCiirLoMu7Ljdrix2xpvg3fYHJzd52zO7nM2xVXFvLXxLRYVLOK3H/6WBz56\ngAm9JjAzdybn9D0Hb1iZb+jlZWCzg8dD4OLzAPA/9Dj27/YRPqkzZbfOZv/g4aSHQxwMHiJi16hR\nfbGN7o/XcTUpyoVn03ZcX3yJfc3nJijefTdaIAcMHlw3KLp2bfpDPTbCKSYSMbWc0lITErE9I3w+\n81hrCQkh2kBSQ0EpdS7wCGAHntNaz633fDrwCtAzWpYHtdYvJLNM3zexoa2prlQzpLXG7PkQCoZw\n2p247e5GO6cBMjwZXDP0Gq4Zeg2bizZbs6d/tvRn+F1+LhpwETPzZjK6+1BURYXZlAcIXPgDKxws\nW/bisjtx2WubcrTWBMMhDkYC6J4Z0HM8tksm4HV4SC0J4F27DucXX2L7/AuYP9/Mqgbo0qVuSAwe\n3PQeD02NcKqpgW+/lRFOQrSBpIWCUsoOPAFMAXYBnyml3tJaF8SddjNQoLW+SCnVEdiolJqvtZYt\nwhJw2p1kebPI9GS2emgrQN/Mvtwx7g5uO/02Pt75sbU50F++/gs56TnMyJ3BjIGX0MOWyeIvX2Pu\nuqfZE9hP15TOzBk6m4EMb3BNpVSDoIjoCDXhIJUpoE/Lg9Nysakr8WoHaZt24o42O9k+/wL+/nfz\nIre7bif2yJEmOBoTP8IpVmtINMLJ7zdhIiOchGiRZNYUxgCbtNZbAJRSC4CpQHwoaMCvzFddH3AI\nSLCzjIh3JENbwdQ+zuh5Bmf0PIMHznqAv3/7dxYWLOTBfz/Ig/9+kH6Z/dhesp1gxCxhsbtyL7ev\n+n/8otds8k6aZtrz7fZGm2tsyobb7sIdt4NcREeoiYTY268Lul8X9IzJ2JUd36Fy/F9uNP0TX+Sj\nXnwRnn7avKh799qaxMiRkJvbeIdzYyOcCgtlhJMQraCamll7RBdWagZwrtb6+ujjq4FTtdaz487x\nA28BJwN+4DKt9d8TXGsWMAugc+fOIxcsWNBm5SwvL8fn87XZ9drK4ZRLowlHwtGZzqZfoqlwqG9f\n1T6W7V/GK9tfIUzDJTkyHBm8NOIFvMoFdfayVuZD+TCa9LXWaGr/DapgiPQtW8hcv5GMgvWkrV+P\n56DZuS7sdlM2YAClubmUDBpE6aBBBDMzKa+qwhfftNT4m9WdXR1botxmi5a/bfskjqd/W0eDlKt1\nWluuSZMmrdFaj2ruvGMdCjOAccCtQF/gfWCo1rq0seuOGjVKr169us3KuWLFCiZOnNhm12srR1Ku\ncCRsDW2tDldjt9mbHdoar/tD3et8UMdTKHpn9iavYx55WSeTlzmAPF8fOukUVPzieA4HOB2m87oV\nIjpCMBIiFAkRQQMaz95DpH21kZS1BTjz16K+Lqh9r5wc9vbtS5fJk01t4uSTW14DCIdNf0Q4bMLC\nbq9dBLANRjgdj/+2kknK1TqtLZdSqkWhkMz6826gR9zj7tFj8a4F5mqTTJuUUlsxtYZVSSzXcS9+\naGt1qJqy6jJraKvb4TbLajehq78ru8vq/6eCdEc614++nnX715G/N5+/ffM367kOKR3I7TCIvOxB\nJihSe9Mn0hFHRGNVIZxO84HdRAdwwqan7ikUd+3CgSmnowFbdTUpBZvxf7UB7xdfk7l6DXzwgTk5\nJQWGD6/tlxgxArKyGvlDtWKEU6zzWkY4ieNcMkPhM6C/Uqo3JgwuB66sd84OYDLwoVKqMzAQ2JLE\nMp1w3A43boebrJQsKoOVHAocsoa2epyJaw9zzpjD7e/fTiAUsI55HV5u6nsTvzjtF9axkqoS1h9c\nz7r961h3wNz+9OWL1mZDHruHgdkDyMuO1ihS+zDI0x2fzY3V5BQLimb6QOoEhTOVyOgMCkcOJXjN\ndLZuL6a/I0Bq/np8X67Hnf819ieeQMX6Evr2rds3MWBA4mCSNZyESF4oaK1DSqnZwHuYIanPa63X\nKaVuij7/FPD/gBeVUl9hvk7eobU+mKwynchsyobP5cPn8lETrqG8ptwMbY2Yoa0eR+2H4fRB0wGY\n+9Fc9pTtoau/K3POmMPA8oF1rpnuSWds97GM7T7WOhYMB9l0aJMVEuv2r2Pp1n/wl/WvW+fkpOeQ\nmz2QvAzT9JSX0ouTXFkoFW3fb6YjO/b7xILCZivDk9OPYK8+7LvoHEKREKqyCs+6DaSsLSB1bQGu\nZe9jez1ahrS02trEqFHmflpawzdp6RpOMsJJHEeSOvxCa70UWFrv2FNx9/cA5ySzDKIhl93VYGhr\neU05aKyhrdMHTbfCIWbdZ+uavbbT7mRQx0EM6jiIGcwATGfynvI9FBwosGoVBfsLWLrlPet1mZ5M\n8rIHkZvRLxoUOfTz9cBpiwZELCiaYFM2PHY32N2Qngqnj6Ny7FhKdIhwJIRj+248+V+SunYD3rXr\ncMybh4pE0EqhBgyou1RH374NQ6klI5xi5XS5zNIdxcW1TWZ2e23HdqxzW4h2RsbkncDqDG2NRIe2\nVrZ8aGtr3qebvxvd/N2Y0meKdbysuoz1B9fXCYuXNrxGddjsVueyuRiY1Z+8jAHk+nLIS+1Nbno/\n0py+6Aevs9mObLvNjh27CYp+A9D9BlAyPcxBHSJSXob7ywI8+V+Tml+A5+2/YZs/HwCdkYEaMaJu\nbSI1teEb1F/DKRIxAVFVZX4eONBwP4nY7OvY0h6xJrRYTaN+gEjtQxxFEgoCqLtqa1WoipKqErPL\nW3Roq91mp5EBSYfN7/YzptsYxnQbYx0LRUJsPrTZBEW0Ceofu1eyILDEOqenv7tpevL3IdfXG2d1\nF3Ir/KjYB2wz7fxWUKS7YfyZBMefSWEkTDBcg23rNtxffEXK2nV48wtw/fOfAGibDU4+GRVfm8jJ\nqf22v3gxzJ1rNhfq2hXmzIGBAxMHSUx8gEQi5lZ/yY7WBEjspxBHQEJB1KGUwuv04nV66Zjakepw\nNcFwkEAwgEZbzUyxcx02Bw6bo8m1mFrDYXMwsMNABnYYyLRB0wDT/LSvYh/r9q+j4GBtreLdncut\nobPp69PIzRxAnr8vuf7e5KX3Z0Bab1wub4uGltptduw2LwwYhB4wiIrLoDQSJlxShGPtV3jyv8ab\n/zXexW9ge/llU67sLBg5EuXxwnvvmU5paH5TophYTaAlWhIg1h8xLjziAyQWGlqb10uAiAQkFESj\n7DY7KbYUcJpO5Q32DfTL6kcoEiIYDlITrqEqVEUgGLBCQymFTdmssGjp3IimKKXo4utCF18XJveZ\nbB2vqKlg/cH1LPtsGUWpRazbv45Xtr1JVcis7uq0Oeif1oe8tL7mlt6f3Iz+ZKRkNTviKfb72zM7\nwMRJ1EycRA1wKFgDmzbh+mItnvx1eNeuw7V1R8MXBwIMnDcP/d0eVHYHMyw2O9tsfJSdbW5ZWXX7\nJ5rSFgESU2N+B6BugMSawuIDRGogJxwJBdEqNmXDZXfhsrtIpbZpJKIjBMNBQpEQVaEqExahAJHY\nzGdtPmRjYdEWfRWprlRGdR2Ft6uXvNHmG3k4EmZr8VZTq4g2Qa3cv4aFO96xXtctpQt5af3IS+9L\nXlp/8rIG0iO9p2l+aobd6YJBuYQH5VJxJVQAJw0chUowCdRWXU34b29hLy5N+DyA9vvQWVnorEzI\nyoasTMjugMrORmVlo2LhEQsSn6/5DurmAsRmM9cBEx6RiAmQysqGARJfE5EAOSFIKIg2YVM2MycC\nN6mu2rAIR8IEI9GwCJqgCIQCRKJDOmM1C6fdiV3Zjzgs7DY7/bL60S+rH1NPnmod31+x3+rQjoXF\nsm8+tkLL70wlN61vNCz6k5c5kP4d+uNxNrOrHBA+qTOOPXsbHK/q1JGij941H7zFJXCoEFVYhK2o\nGNuhQ9GfRdiLirEXlWDfsxP7uq+xFxVjq068JqR2OolkZaIzM6zaho6GRixIyM7GlpWN6tDB1Eya\nCrvYh3pzYk1O9QMkNn8jdk6iAImtMxUfIPFBItoVCQWRVKat3nzo+Fy167TEmqBCkZAJimCAylAl\nER2xgiFWq2hu9deW6JTaiU6pnZiYM9E6FggG2HBwg9WhXbC/gAU736Vy62JTdmWnv68nuen9yEsf\nQF7WQPI6DDJ7YMcpu3U2f59/D3dNCLEjHXqWwG9XOhg65Udkg/kAzM6C7Cx0fwhDgpWl4miNqgxg\nKypGFR7CVlSEOlSEOnQIVVSM/VARtkPFJkx27TSBUlrW6OXC6WlEsjLQmZmQlUV/h5vq3j2jQZIF\nmVmoaO3E1qEjKiW1YTgrdXgBEggkDpB4sXCoqYEdOxoO3a1fC4mtU1X/lug50WoSCuKYiP+w97v9\ngOlQDkXXPYr1V1QGK6kKVaG1thb4a6vOba/Ty/CThjP8pNolwSM6wrbibdbEu4L96/j4wFcs3vW+\ndU4XT0fy0qM1iqyB7O53kD9MVcTmf2/PgFlTFb/oC7/gMCiFTk0hnJoC3bu27DXBILbiEqv2YYsG\nhwmSIuyHirEVFWHbuYPsA0W4li1DhRIvSBzxuAllpBPJyiSSlQFZWUSyslBZWdGmrSyINm2p7Gxs\nmVkomx2bspk+pPgAaWxV2/qjte64w6xbFZsgGOtEjzVl1W/WitfUBkuJQqX+sabCJtYxHwqdMIEj\noSDaDaUUTrsTp92J1+klnXTAfFDHwqI6VF2nczv2fGWwsk06t23KRp/MPvTJ7MNFAy6yjhdWFpra\nxIEC1u37ioIDBaz4dhVhnfg7f4Agj2/7I15/iDRXGunuNNJcfnNz+khz+fE7Utts1BZOJ5GOHYh0\n7NDsqeu27CWvd2dUeTm2Q8W1QWLVQopQRcXYorUU2/Zd5nhFZcLraZuNcLqfYGYG4WiNxASKqZnE\n+kVUdgdsHTri+L9/4/rv36AC0e1ed+9G33EHnX7xC8KDTkYphYqul3XEfU+xWkvsZ2zxw0S3xtTU\nwJYEq+80V6OJf765Gk07ChwJBdHuxXdup8S18cc6t3fZdpHlNduWVoWqaj+o27BzOzslmzN7ncmZ\nvc60jlWFqvim8BvOm39ewtdUhCu5J39ek9f1O1JNSDhTSXPWBka6y48/GiLp7jTzXFygpDt9+F0+\nM+P7cCiF9vsJ+/2Ee/Vo/nyAmhoTIrEAKSqKhkpRXKgUY9u6Hdvna7EVlaBiy4E0V5xAgIEPPUTV\nhx+gnc7am8vccJqZ5NrpBHftfeV2gdOFdjlRruh6VG4XyumG6DHldqFdLmxON8rtqZ2V7nKhXC5U\ntElMQZ0wit3XNkUoxRM9R9WeqzFNfVA3cGK/c6LAaapWE3suPkhi9998E373OzPcuWdPuP9+6Nat\nZf/dWklCQXxvxTq3bcpm2vmjC5421rkdjoSt/6ntNvsRd257HB5O6XwK3fzdEq4q28ndieXXLae0\nutTcqkoorSoxEwOrSiirLqWkusR6vqSqhD01hWws30ZpTRmlwfLa0VuN8No9pDt9VliY8Ijed6WR\nHg0Wv9NnznP52R+oplPAid/lM8uCtJTLRaRLJyJdOrXs/EgEVVpmOtMPFVk1kvT/vj/h1hu2YBBn\noAZKK1A1NaiaIASDDe+HmuyRaTXtsKOdLrTTYUIoLoy008kwbaPG52lwvH5oWeEVDSGcTmsJduV2\nm+ByusHjNsdcblQ03GweTzTITFDhcKJcTlREYX/zb7jvvBtVFa1Zbd8Os2bR6Ze/hCQs6S2hII47\nTXVuxzq427Jzu7FVZa/NuZYMTwYZnozD+j0iOkJFTUU0UIrrBEppVUmdsCmJ3i+sKWZL+Q5Ka8op\nDZYRaqR5i7Xmh9vmigaKLy5Q0qK1EfPY7/SZcInWVtJjIePy47U3sRSKzYbOSCeckU64T4512Pfk\nn3gtey93TsbqmL//A5i+ryNFr7Vgi/ZIpDYggiGIhoaqCZr7wWC9QKmBYCh6fhBqgo3fj74m/n6k\ntAI7ClURgOJS817BYO37xt9vYc2opbTDAeFwwyHNlZX0ee45+O1v2/T9QEJBnEBiH/Yeh6dNO7db\nuqpsa9mUDb/bj9/tp1ta65sKtNYEgpWUBqKBEiimtLqEgm+/Ja2TNxouxVaglNaUUlpTzq7y7ygN\nllMSLKMmEmzyPRzK3qBpywSHCRkrUOJqMfk3D+HByr0Eoi1f2zNg1sWwMzKaa1r0h7GB2412u9t6\n5ZWE1m3ZS16fJvYLjxcO1w2huPtEw6o2hGpQNSFUsKb2fr3zCAbxPfMi84fQIESv/Hp/Un5fCQVx\nQmusc1trbTVB1YRqrCaoWOc2ijoztw93VdlkUkqR4kolxZVKl/TaUOlS2tOa7NeoaFt4VU0lZVUl\nlARKKI02dZVUlVAWDRizRlZZNFDKKK0pY3/l/miolBMIVyW+fr2ukEon/JqlPLBwJQ7lwBn9u7ps\nThw2B07rmBOnzWHdHMph/vupeufXe71DOXDZnda1ndHrOOLvK0fctZ3R1zvYXlmCuySAs7HXq7gv\nC3Y72usFb9stFfbX9Yu5aXwpldHJ79szYNZFEEzz8+M2eo94EgpCJKCUqtO5nYFpAoqfuV0drrY6\nt0OREEopq3aBMucGggGr09KmbNZkvdbun33URUfBeDw+PB4fHTNaUVOJW1ojGKw2oRJtAiupKuGK\nd65r9KX/kXOhqbnpEMFwiGAkSFBHa3KREKFIkKAOUxWqojwSIhiJnhMJEdJh63FIhwhG+5aCOvHQ\n21b5sumnbdiiwWKPCxl7XKjZraBxqnqhZos+F/daK+SUg5cnV1N/3FelC/7rbCQUhDjW6szcJrVB\n53Y4Ekaj0Vqz07aTDE+G2W86Oqw2oiPUhGuIELFmdVu9rrGvlvGPozWSWIh8L8Ilbqay0+kkK8VH\nFrWh0u2jxjvm77vooTYvjtaasA4TDNXU1v7CNdH+pRqC4WioRIImiMK15wXDQbZs2sZJvTpREwkS\nip4btO7HrhesfX2kxtpn3FzLXLsm+mUi9vrKcDXBcAWhYDB67VjAxZ0XrqGGxE14e1XjExaPhISC\nEG0gvnPbOqbsZKdkN/oarbUVIBEdQRP9Gfc4HAkT0RHCkTBhHU4cLjoCGmtBwkTholRtqGitqQ5V\nH7NwaapjPhmUUjiUA4fLgbf50xtYV7KOvKZWu02yMc+OaTREk6HFoaCUOgPor7V+QSnVEfBprbcm\npVRCnACssfAKs7/DYYqFS/1ASRQuoUjImvcRC5uQDtUJF1M4rKaw+LCJD5f6gdLScElWx/zxKlGI\npjhTuL739Ul5vxaFglLqN8AoYCDwAqab6BVgXFJKJYRosfhmpZZw2BwJRzM1Fi6xx/XDpf7PkA4R\n1qb5LFFtJRYuWmt+0PcHnNvvXGveCMDmLzZTFapKOJu5/rH419U/1u6a045Q/RDtmd6T+yffT7fC\nYzt5bRowHPgczN7KSil/UkokhDgmWhsujWkuXCI6Yt2sPhg0NmUj1ZlqTdiL/YxdL/5YbNa6jhu/\nHyH6uvp9NZC4v4a4JrcE58RqSpFIxGwu1cQ58ceaCqz6x+Ofayrcpg6cyvn9z8dtd1uBvmLFCpKh\npaFQo7XWSikNoJRqYo9BIcSJ7HDDxWFz0NnXuc3KER8YsVCJHav/uKlzdjt20yOtR5PnxB+rH2qJ\njrXmnFgoKhTu1sxAP0wtDYXXlVJPAxlKqRuAnwDPJq9YQghxZBJ9G0+4vkZz18FsUXuiaFEoaK0f\nVEpNAUox/Qp3a63fb+ZlQgghvmeaDQWllB1YprWeBEgQCCHEcazZRj+tdRiIKKXSj0J5hBBCHEMt\n7VMoB75SSr2P2ascAK31YW0sJYQQon1qaSgsjt6EEEIcx1ra0fySUsoFDIge2qi1bnpNXUApdS7w\nCGAHntNaz633/G3AVXFlGQR01FofamH5hRBCtKEWDSRWSk0EvgWeAP4IfKOUOrOZ19ij558H5AJX\nKKVy48/RWv9Baz1Maz0M+DWwUgJBCCGOnZY2H/0vcI7WeiOAUmoA8CowsonXjAE2aa23RF+zAJgK\nFDRy/hXRawohhDhGVPyMvkZPUupLrfUpzR2r9/wM4Fyt9fXRx1cDp2qtZyc4NwXYBfRLVFNQSs0C\nZgF07tx55IIFC5otc0uVl5fj8/maP/Eoa4/lao9lAilXa0m5Wud4KdekSZPWaK1HNXui1rrZG/A8\n8BwwMXp7Fni+mdfMwPQjxB5fDTzeyLmXAX9rSVlGjhyp29Ly5cvb9HptpT2Wqz2WSWspV2tJuVrn\neCkXsFq34DO2pc1HPwVuBmJDUD/E9C00ZTfQI+5x9+ixRC5Hmo6EEOKYa2koOIBHtNYPgdWJ3NzK\nTJ8B/ZVSvTFhcDlwZf2TopPiJgA/bGmhhRBCJEdLlzH8AOpsWuQFljX1Aq11CJgNvAesB17XWq9T\nSt2klLop7tRpwD+01hWJriOEEOLoaWlNwaO1Lo890FqXRzuHm6S1XgosrXfsqXqPXwRebGE5hBBC\nJFFLawoVSqkRsQdKqVFAoInzhRBCfA+1tKZwC7BQKbUn+vgkzIghIYQQx5EmawpKqdFKqS5a68+A\nk4HXgCDwLrD1KJRPCCHEUdRc89HTQE30/mnAf2GWrigCnkliuYQQQhwDzTUf2XXtDOPLgGe01m8A\nbyil8pNbNCGEEEdbczUFu1IqFhyTgX/GPdfS/gghhBDfE819sL8KrFRKHcSMNvoQQCnVDyhJctmE\nEEIcZU2Ggtb6fqXUB5jRRv+Irp8Bpobx82QXTgghxNHVbBOQ1vqTBMe+SU5xhBBCHEstnbwmhBDi\nBCChIIQQwiKhIIQQwiKhIIQQwiKhIIQQwiKhIIQQwiKhIIQQwiKhIIQQwiKhIIQQwiKhIIQQwiKh\nIIQQwiKhIIQQwiKhIIQQwiKhIIQQwiKhIIQQwiKhIIQQwiKhIIQQwpLUUFBKnauU2qiU2qSUmtPI\nOROVUvlKqXVKqZXJLI8QQoimNbsd5+FSStmBJ4ApwC7gM6XUW1rrgrhzMoA/AudqrXcopTolqzxC\nCCGal8yawhhgk9Z6i9a6BlgATK13zpXAYq31DgCt9f4klkcIIUQzkhkK3YCdcY93RY/FGwBkKqVW\nKKXWKKWuSWJ5hBBCNENprZNzYaVmYJqFro8+vho4VWs9O+6cx4FRwGTAC/wbuEBr/U29a80CZgF0\n7tx55IIFC9qsnOXl5fh8vja7Xltpj+Vqj2UCKVdrSbla53gp16RJk9ZorUc1e6LWOik34DTgvbjH\nvwZ+Xe+cOcC9cY//BMxs6rojR47UbWn58uVter220h7L1R7LpLWUq7WkXK1zvJQLWK1b8NmdzOaj\nz4D+SqneSikXcDnwVr1z3gTOUEo5lFIpwKnA+iSWSQghRBOSNvpIax1SSs0G3gPswPNa63VKqZui\nzz+ltV6vlHoX+BKIAM9prb9OVpmEEEI0LWmhAKC1XgosrXfsqXqP/wD8IZnlEEII0TIyo1kIIYRF\nQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEI\nIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRF\nQvLdsfUAAAsrSURBVEEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYRFQkEIIYQlqaGg\nlDpXKbVRKbVJKTUnwfMTlVIlSqn86O3uZJZHCCFE0xzJurBSyg48AUwBdgGfKaXe0loX1Dv1Q631\nhckqhxBCiJZLZk1hDLBJa71Fa10DLACmJvH9hBBCHCGltU7OhZWaAZyrtb4++vhq4FSt9ey4cyYC\nizE1id3Ar7TW6xJcaxYwC6Bz584jFyxY0GblLC8vx+fztdn12kp7LFd7LBNIuVpLytU6x0u5Jk2a\ntEZrParZE7XWSbkBM4Dn4h5fDTxe75w0wBe9fz7wbXPXHTlypG5Ly5cvb9PrtZX2WK72WCatpVyt\nJeVqneOlXMBq3YLP7mQ2H+0GesQ97h49Fh9IpVrr8uj9pYBTKdUhiWUSQgjRhGSGwmdAf6VUb6WU\nC7gceCv+BKVUF6WUit4fEy1PYRLLJIQQoglJG32ktQ4ppWYD7wF24Hmt9Tql1E3R55/CNDH9VCkV\nAgLA5dFqjhBCiGMgaaEAVpPQ0nrHnoq7/zjweDLLIIQQouVkRrMQQgiLhIIQQgiLhIIQQgiLhIIQ\nQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiL\nhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQ\nQgiLhIIQQgiLhIIQQgiLhIIQQgiLhIIQQghLUkNBKXWuUmqjUmqTUmpOE+eNVkqFlFIzklkeIYT4\n/9s791gp6iuOf74FfJRHrVIJAVMxkpaLD4pAG0sVa7RCTa2xLzX9o5KgjRKs6YPWxGAkqWht0dZU\nsbWFYouNojUktIoxthQtAvK8lIpK01IeNYYqDaDI6R+/s8uw7Nze5e7u7L33fJLJnvnNb37z3bMz\nc/Y3v5kzQcc0LChI6gPcD0wG2oCrJbXl1JsDPN0oLUEQBEHnaGRPYQKw1cxeM7N3gEXAFVXqTQce\nB3Y3UEsQBEHQCfo2sO1hwD8y8/8EPp6tIGkYcCVwETA+ryFJ04BpPrtX0pY66hwMvFHH9upFK+pq\nRU0QumoldNVGT9H14c5UamRQ6Axzge+Y2SFJuZXMbB4wrxECJK0ys3GNaLsrtKKuVtQEoatWQldt\n9DZdjQwK24HTMvPDvSzLOGCRB4TBwBRJB83syQbqCoIgCHJoZFB4CRgpaQQpGHwFuCZbwcxGlGxJ\nvwSWREAIgiAojoYFBTM7KOkm4A9AH+BhM9sk6QZf/kCjtl0jDbksVQdaUVcraoLQVSuhqzZ6lS6Z\nWSPaDYIgCLoh8URzEARBUCaCQhAEQVCmxwcFSdskbZC0VtIqLztZ0jOSXvHPD2bqf9fTcmyR9Jk6\n6nhY0m5JGzNlNeuQdJ5/n62S7lNH9/Ieu65Zkra7z9ZKmtJMXZJOk/ScpHZJmyTN8PJC/dWBrqL9\ndYKklZLWua7bvbxof+XpKtRfmTb7SHpZ0hKfL/x4zNHVXH+ZWY+egG3A4Iqyu4CZbs8E5rjdBqwD\njgdGAK8Cfeqk4wJgLLCxKzqAlcAnAAFLgckN0DUL+GaVuk3RBQwFxro9EPibb7tQf3Wgq2h/CRjg\ndj/gL9520f7K01WovzLbuwX4NemuR4r2Vwe6muqvHt9TyOEKYL7b84HPZ8oXmdkBM3sd2EpK19Fl\nzOyPwJtd0SFpKDDIzF609MsvyKxTT115NEWXme0wszVuvw1sJj0hX6i/OtCVR7N0mZnt9dl+PhnF\n+ytPVx5N2+8lDQc+C/ysYvuFHo85uvJoiK7eEBQMWCZptVK6DIAhZrbD7Z3AELerpebo6KDvKrXq\nGOZ2M/RNl7Re6fJSqRvddF2STgc+RvqX2TL+qtAFBfvLLzmsJeUQe8bMWsJfObqg+P1rLvBt4FCm\nrHB/5eiCJvqrNwSFiWY2hpSt9UZJF2QXeiQt/L7cVtHh/BQ4AxgD7ADuKUKEpAGkZIk3m9lb2WVF\n+quKrsL9ZWbv+X4+nPRv8ayK5YX4K0dXof6SdDmw28xW59Upwl8d6Gqqv3p8UDCz7f65G3iCdDlo\nl3ex8M9ShtbOpOaoJ7Xq2O52Q/WZ2S4/mA8BD3H4ElrTdEnqRzrxPmJmi724cH9V09UK/iphZnuA\n54DLaAF/VdPVAv76JPA5SdtI2Zs/LWkhxfurqq6m+6uzgw/dcQL6AwMz9grSwXI3Rw4o3eX2aI4c\nuHmNOg00e/unc+SAbs06OHoAaUoDdA3N2N8gXbdsmi5vYwEwt6K8UH91oKtof30IOMntE4E/AZe3\ngL/ydBXqrwqNkzg8oNsSx2MVXU31V5fFt/JE6nKt82kTcKuXnwI8C7wCLANOzqxzK2kUfwt1uJMg\n0+5vSF2/d0nX+KYeiw5SEsGNvuwn+FPpddb1K2ADsB54qmKnbLguYCKp674eWOvTlKL91YGuov11\nDvCyb38jcNux7udN0lWovyo0TuLwybfw4zFHV1P9FWkugiAIgjI9fkwhCIIg6DwRFIIgCIIyERSC\nIAiCMhEUgiAIgjIRFIIgCIIyERSClkPSKZmMkDsrMkQe18k2fiHpI/+nzo2Srq2P6tZA0nJJY4rW\nEXRf4pbUoKWRNAvYa2Y/qCgXaf+tzBHTq5G0HLjJzNYWrSXonkRPIeg2SDpT6V0Gj5AeRhwqaZ6k\nVUr5+m/L1F0uaYykvpL2SLpTKa//C5JO9TqzJd2cqX+nUv7/LZLO9/L+kh737T7m2zrqn7ik8ZKe\n98SLSyUNkdTP5yd6nbt1+J0Ct0t6SdJGSQ+U8t27jh/6dtoljZP0hFKO/1kZP2yStEjSZkm/lXRi\nFU2T/fuukfSopP4ZHe2eYG1OXX+koNsTQSHobnwU+JGZtVnKazXTzMYB5wKXSGqrss4HgOfN7Fzg\nBeC6nLZlZhOAbwGlADMd2GlmbcAdpMyoR64kHQ/cC1xlZucBC4E7zOxd4GvAPEmXAhcBs321e81s\nPHC267ss0+Q+/04/B54EbvB60ySd5HXaSOk2RgH7gesrNJ1KStVwsZmNJT0NO0PSENJT2KPN7Bzg\n+zm+CHopERSC7sarZrYqM3+1pDXAGmAU6WRZyT4zW+r2alKup2osrlJnIik5GWZWSpdSyShSHppl\nniZ6Jp6ozMzW+/q/A67zQAFwsaSVpBQsF/r6JZ7yzw3ABksJ0faTXhhVSnT2upm96PZC15nlfJIv\nVrima/07vUlKy/yQpCuB/+b4Iuil9C1aQBDUSPkkJmkkMAOYYGZ7PNPlCVXWeSdjv0f+fn+gE3Wq\nIWC9mX0qZ/lZwH+A0mWr95Py0Yw1s+2SZlfoLuk4lLFL8yVdlYOBlfMCfm9mXz1KrDQOuAT4IvB1\n4NL8rxb0NqKnEHRnBgFvA295quO6vVM7w5+BLwFIOpvqPZF2YJikCV7vOEmj3f4yMICU4Ox+SYNI\nGUMPAW9IGghcdQy6Rkga7/Y1wPKK5SuACyWd4Tr6Sxrp2xtkZktIGTePuhwW9G6ipxB0Z9aQTsh/\nBf5OOoHXmx8DCyS1+7baSf/6y5jZAUlfAO7zk34f4B5J/yaNQ0wys39JepA0HjJV0nxvaweH395W\nC5uBW3zQewMwr0LTLklTgUczt/F+D9gHLPZxkPeR3gccBGXiltQg6ABJfYG+ZrbfL1c9DYw0s4MF\najoTeMzSG82CoK5ETyEIOmYA8KwHBwHXFxkQgqDRRE8hCIIgKBMDzUEQBEGZCApBEARBmQgKQRAE\nQZkICkEQBEGZCApBEARBmf8B4esAd/zG9OQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a151bc8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFi1JREFUeJzt3XtwnfV95/H3VzdbF98lLr4hG5wQk5QtKCRNWXCTKbGd\nZJjOZLZALlsmWZe0dHaa7Cy03SYzm/0jHXZmAyHg8RJCup0JaQNNSOOE5gIBQriYFGyMFxC2wbeA\nbFjbkTG20G//0LF8JMvSsXzOkc5P79eMZnSe52c9v9/IfPzwec55nkgpIUnKS91ET0CSVH6GuyRl\nyHCXpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDDRN14Pb29tTZ2TlRh5ekmvTUU0/tTSl1\njDVuwsK9s7OTDRs2TNThJakmRcTLpYyzlpGkDBnukpQhw12SMmS4S1KGDHdJytCY4R4Rd0bEaxHx\n7En2R0TcEhHdEbExIi4q/zQlSaeilDP3u4CVo+xfBSwrfK0Bbj/9aUmSTseY73NPKT0UEZ2jDLkS\n+Ps08Ly+xyJidkScnVLaU6Y5DtH92m+575ndLG1vpbO9lSXtrcxqbqzEoSSpZpXjQ0wLgB1Fr3cW\ntp0Q7hGxhoGzexYvXjyug23Zc4Bbf/4i/UWPfp3X2sSSQtAv6WhlaXsrS9rbOGdeC9Mb68d1HEmq\nZVX9hGpKaR2wDqCrq2tcT+b+2IXzueKCM9nx+iG29vSybe/A19a9vTz4Qg//9NTOwbERMH9WM0s7\nWumcNzT8F8xupqHe68mS8lSOcN8FLCp6vbCwrWKmNdRz3hkzOO+MGSfsO3j4KC/vO8TWvb1s6+ll\n297fsm1vL9/7t10cfKtvcFxjfbB4bgtL2ttY2tE6eOa/tL2VjhnTiIhKLkGSKqoc4X4fcH1E3A28\nD9hfqb69FDOmN/LuBbN494JZQ7anlNjXe2TgTL+nl237joV/Lw+92MORvv7Bsa1N9YN9/tLC2f6S\n9jb7fUk1Y8xwj4hvAyuA9ojYCXwJaARIKa0F1gOrgW7gEHBtpSZ7OiKC9rZptLdN472dc4fs6+9P\n7N7/5vGKpxD6G3fuZ/2mPWP2+53tA7WP/b6kySIG3uRSfV1dXakW7gr5Vt/b7Hj9ENv2HhqseI6F\n/2sH3xocd6zfHwx++31JFRART6WUusYaN2G3/K0VQ/v9M4fs++1bfWwvXMwd0u8/vYuDh0fu95e0\ntwxWPEs7WjnDfl9SBRjup6FtWsNJ+/3XC/3+1kLVc7J+v6WpfsjF3MF+f14rs1rs9yWNj+FeARHB\nvLZpzGubRlcJ/f72fb1s2nVivz+3uN8vCn/7fUljMdyrrK4uWDinhYVzWvj3y4Y+KetIXz+vvH6o\nEPzH+/2HXujhu0Xv3wdYMHtYv1/4WjjHfl+S4T6pNDXUcd4ZbZx3Rhsn6/e37R36wa2R+v1Fc1sK\nn9Jttd+XpijDvUaMp99/+MW9vDVCv995rOIZrHva7PelzBjuNW6sfn/PgcOD7+Q5Fv7P7trPj+z3\npawZ7hmrqwsWzG5mwexmLl3WPmTfSP3+wNn+if3+/FnTC+/iGah5ltrvS5Oe4T5Fjaffv+/p3Rwo\n6vcb6oLF8473+51FNc+ZM+33pYlkuOsEpfT7w79G6vc75xXfgtl+X6omw10lG2+//+Nnf8PbRQX/\nsX6/c17rkDtyds5rpbnJfl8qB8NdZTFWv7/jjUOD7+LZWuj5H+nu4Z5fj93vdxb6/Ub7falkhrsq\nrqmhjnM72ji3o+2Efb1v9Y1Y84zY789tGXJTNvt96eQMd02o1lH6/TcOHR2oeHqGBv8j3aP3+8Xf\nz25pqvaSpEnBcNekFBHMbW1ibutcLj5nlH5/8KErv2XzCP3+nJbG4xWP/b6mEMNdNaec/X5n8Tt5\nCnfktN9XDgx3ZWWsfn/7vqG3aNi6t5cfPGO/r/wY7poyWqc1cMH8WVwwf+x+f/u+gTty/vKlvRw+\nerzfb26sP+HePPb7mowMd015Y/X7vzlw+HjFc6zf372fH28+eb9f/MStzvYWWpr8T03V5d84aRR1\ndcH82c3Mn93M75938n5/+77j4f/L7r3c8+vDQ8aePWv60Buz2e+rwgx3aZzG0+//y8Y97H/z6OC4\nY/3+kAu7harnzBnTqauz39f4GO5SBZys3wd4o/fI8XvvFz1x69ES+v1jr+e02u9rdIa7VGVzWpu4\nuLWJi8+ZM2T7SP3+9n29PLfnwAn9/uzBfv9Y+Nvvayj/FkiTxGj9/tG3+9kxeP/94+H/aPc+7v31\nriFjh/f7x74WzW2x359CDHepBjTW17G0o42lo/T72/ceGnJHzuH9fv3w9+/b72fNcJdqXLn6/XPm\ntRTdoqFtMPzt92uT4S5lbLR+/9WDA/fn2Vp0U7Ytew5y/+ZX7fcz4G9GmoLq6oKzZzVz9qxmPlBC\nv799by+/eunEfv+smdOHfErXfn/yMNwlDTFav3/oSF+h2x/6xK0fjtLvD3/c4lkz7ferwXCXVLKW\npgaWz5/J8vkzT9h3rN8vfrj61r0n9vvTG+uGPWLRfr8SSgr3iFgJ3AzUA3eklL4ybP8s4B+AxYWf\n+T9TSt8s81wlTWLl6vc75xVVPEX34LffPzWRUhp9QEQ98ALwh8BO4Eng6pTSc0Vj/hqYlVK6ISI6\ngOeBs1JKR072c7u6utKGDRvKsARJtero2/3sfOPNEZ+4tWf/0PvzDO/3j9U9i+a00NQwdfr9iHgq\npdQ11rhS/im8BOhOKW0t/OC7gSuB54rGJGBGDNzoug14Hegb/oMkqVhjfd3gmfkHzx+6b3i/v63w\nPv4fbdrDG4eG9vuL5jQfr3js94HSwn0BsKPo9U7gfcPG3ArcB+wGZgB/nFLqR5LGaax+//gjFo/3\n+7/aum/Efv+K5Wfy+SveWc3pT7hylVgfBp4GPgicC/wkIh5OKR0oHhQRa4A1AIsXLy7ToSVNNXNa\nm5jT2sRFi0/e7x8L/59ueZVv/eplw30Eu4BFRa8XFrYVuxb4Shoo8LsjYhtwPvBE8aCU0jpgHQx0\n7uOdtCSNZKT37/f1J/7534ZHVv5KuQrxJLAsIpZERBNwFQMVTLFXgA8BRMSZwDuBreWcqCSpdGOe\nuaeU+iLieuB+Bt4KeWdKaXNEXFfYvxb4MnBXRGwCArghpbS3gvOWJI2ipM49pbQeWD9s29qi73cD\nV5R3apKk8Zo6bw6VNGW9eeRtHnlxapUJhrukrP2HrkWcMXMan/zG4/zJN5/g+d8cnOgpVYXhLilr\ny+fP5GdfuJy/Wf0ufv3yG6y6+SFuvGcjrx04PPYfrmFj3n6gUrz9gKRqe6P3CF/7eTf/57HtNNbX\nseaypay5bGlN3bem1NsPeOYuacqY09rEFz+2nJ9+/nJWvLODr/70RVbc9CDfefKVITcwy4HhLmnK\nOWdeK7d94mLu+dzvsWBOMzfcs4mP3PIwv3ihZ6KnVjaGu6Qp6+Jz5nLv5z7AbZ+4iENH3uY/3vkE\nn/rG42zZc2DsPzzJGe6SprSIYPV7zuYnn7+Mv/3ocjbu3M/qWx7mv373GV6t4YuuXlCVpCL7Dx3l\n1gde5FuPvkx9XfCfLlvKn162lNZpk+OiqxdUJWkcZrU08jcfGbjo+qF3ncEtP3uRy296kG8/8Qp9\nb9fOncwNd0kaweJ5Ldx6zUXc+2cfoHNeC3917yZW3fwwD/zf15ioxuNUGO6SNIqLFs/hn677PdZ+\n8iKOvt3PtXc9ySe/8Tibd++f6KmNynCXpDFEBCvffTb/+peX86WPLWfz7gN89GuP8IV/fIY9+9+c\n6OmNyAuqknSK9r95lNse6Oabv9xOXR189tKlXLfiXNqqcNHVC6qSVCGzmhv5q9Xv4mdfuJwPX3AW\ntz7QzYqbHuAfHnt50lx0NdwlaZwWzW3h5qt+l+//+e+ztL2N//a9Z1l588P8bMurE37R1XCXpNN0\n4aLZfOdP38+6T11Mf3/iM9/awDX/+3Ge3TVxF10Nd0kqg4jgigvO4v6/vIz/fuUFPP/qQT76tUf4\n/HeeZtf/q/5FVy+oSlIFHDh8lNsffIlvPLKNAD5z6RI+t+JcZkxvPK2f6wVVSZpAM6c3csPK83ng\nv6xg9XvO5rYHX2LFTQ/yw417qnJ8w12SKmjB7Gb+1x//O35w/aXMbW3if/zwuaoc13CXpCp4z8JZ\ndHXOpa9KDwUx3CUpQ4a7JGXIcJekDBnukpQhw12SMmS4S1KV1NdBv++WkaS8NNbXcaSvOneNNNwl\nqUqaGup4q0q3BDbcJalKphXO3KtxT6+Swj0iVkbE8xHRHRE3nmTMioh4OiI2R8QvyjtNSap9TQ0D\nkVuNT6mO+UyoiKgHvg78IbATeDIi7kspPVc0ZjZwG7AypfRKRJxRqQlLUq1qrB8I9yN9/YPfV0op\nP/0SoDultDWldAS4G7hy2JhrgHtTSq8ApJReK+80Jan2HTtzr8ZF1VLCfQGwo+j1zsK2Yu8A5kTE\ngxHxVER8eqQfFBFrImJDRGzo6ekZ34wlqUYNhnsVLqqW6/8LGoCLgY8AHwb+NiLeMXxQSmldSqkr\npdTV0dFRpkNLUm1oqq/emfuYnTuwC1hU9HphYVuxncC+lFIv0BsRDwEXAi+UZZaSlIHJdub+JLAs\nIpZERBNwFXDfsDHfBy6NiIaIaAHeB2wp71QlqbZNqjP3lFJfRFwP3A/UA3emlDZHxHWF/WtTSlsi\n4sfARqAfuCOl9GwlJy5JtaaaF1RLqWVIKa0H1g/btnbY65uAm8o3NUnKS11dANA/WT7EJEmqLYa7\nJGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJkuEtS\nhgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXI\ncJekDBnukpQhw12SMmS4S1KV9afKH6OkcI+IlRHxfER0R8SNo4x7b0T0RcTHyzdFScpD27QGAA4d\n6av4scYM94ioB74OrAKWA1dHxPKTjPs74F/LPUlJysHM6Y0AHHhzEoQ7cAnQnVLamlI6AtwNXDnC\nuL8A7gFeK+P8JCkbs5oL4X74aMWPVUq4LwB2FL3eWdg2KCIWAH8E3F6+qUlSXmY2D9Qy+9+cHOFe\niq8CN6SU+kcbFBFrImJDRGzo6ekp06ElqTY0N9ZTXxccrMKZe0MJY3YBi4peLyxsK9YF3B0RAO3A\n6ojoSyl9r3hQSmkdsA6gq6urCteLJWnyiAjq64K3Rz0NLo9Swv1JYFlELGEg1K8CrikekFJacuz7\niLgL+JfhwS5Jqp4xwz2l1BcR1wP3A/XAnSmlzRFxXWH/2grPUZJ0iko5cyeltB5YP2zbiKGeUvqT\n05+WJOl0+AlVScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUp\nQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJk\nuEtShgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyVFK4R8TKiHg+Iroj4sYR9n8iIjZG\nxKaIeDQiLiz/VCVJpRoz3COiHvg6sApYDlwdEcuHDdsGXJ5Seg/wZWBduScqSSpdKWfulwDdKaWt\nKaUjwN3AlcUDUkqPppTeKLx8DFhY3mlKkk5FKeG+ANhR9HpnYdvJfAb40Ug7ImJNRGyIiA09PT2l\nz1KSdErKekE1Iv6AgXC/YaT9KaV1KaWulFJXR0dHOQ8tSSrSUMKYXcCiotcLC9uGiIjfAe4AVqWU\n9pVnepKk8SjlzP1JYFlELImIJuAq4L7iARGxGLgX+FRK6YXyT1OSdCrGPHNPKfVFxPXA/UA9cGdK\naXNEXFfYvxb4IjAPuC0iAPpSSl2Vm7YkaTSl1DKklNYD64dtW1v0/WeBz5Z3apKk8fITqpKUIcNd\nkjJkuEtShgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUp\nQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJk\nuEtShgx3ScqQ4S5JGTLcJSlDJYV7RKyMiOcjojsibhxhf0TELYX9GyPiovJPVZJUqjHDPSLqga8D\nq4DlwNURsXzYsFXAssLXGuD2Ms9TknQKSjlzvwToTiltTSkdAe4Grhw25krg79OAx4DZEXF2mecq\nSSpRKeG+ANhR9HpnYdupjpEkVUlVL6hGxJqI2BARG3p6eqp5aEmaFFZecBbnnzWj4sdpKGHMLmBR\n0euFhW2nOoaU0jpgHUBXV1c6pZlKUgZuufp3q3KcUs7cnwSWRcSSiGgCrgLuGzbmPuDThXfNvB/Y\nn1LaU+a5SpJKNOaZe0qpLyKuB+4H6oE7U0qbI+K6wv61wHpgNdANHAKurdyUJUljKaWWIaW0noEA\nL962tuj7BPx5eacmSRovP6EqSRky3CUpQ4a7JGXIcJekDBnukpShGHijywQcOKIHeHmcf7wd2FvG\n6dQC1zw1uOap4XTWfE5KqWOsQRMW7qcjIjaklLomeh7V5JqnBtc8NVRjzdYykpQhw12SMlSr4b5u\noicwAVzz1OCap4aKr7kmO3dJ0uhq9cxdkjSKSR3uU/HB3CWs+ROFtW6KiEcj4sKJmGc5jbXmonHv\njYi+iPh4NedXCaWsOSJWRMTTEbE5In5R7TmWWwl/t2dFxA8i4pnCmmv67rIRcWdEvBYRz55kf2Xz\nK6U0Kb8YuL3wS8BSoAl4Blg+bMxq4EdAAO8HHp/oeVdhzR8A5hS+XzUV1lw07ucM3J304xM97yr8\nnmcDzwGLC6/PmOh5V2HNfw38XeH7DuB1oGmi534aa74MuAh49iT7K5pfk/nMfSo+mHvMNaeUHk0p\nvVF4+RgDT72qZaX8ngH+ArgHeK2ak6uQUtZ8DXBvSukVgJRSra+7lDUnYEZEBNDGQLj3VXea5ZNS\neoiBNZxMRfNrMof7VHww96mu5zMM/Mtfy8Zcc0QsAP4IuL2K86qkUn7P7wDmRMSDEfFURHy6arOr\njFLWfCvwLmA3sAn4zyml/upMb0JUNL9KeliHJp+I+AMGwv3SiZ5LFXwVuCGl1D9wUjclNAAXAx8C\nmoFfRcRjKaUXJnZaFfVh4Gngg8C5wE8i4uGU0oGJnVZtmszhXrYHc9eQktYTEb8D3AGsSintq9Lc\nKqWUNXcBdxeCvR1YHRF9KaXvVWeKZVfKmncC+1JKvUBvRDwEXAjUariXsuZrga+kgUK6OyK2AecD\nT1RnilVX0fyazLXMVHww95hrjojFwL3ApzI5ixtzzSmlJSmlzpRSJ/Bd4M9qONihtL/b3wcujYiG\niGgB3gdsqfI8y6mUNb/CwP+pEBFnAu8EtlZ1ltVV0fyatGfuaQo+mLvENX8RmAfcVjiT7Us1fNOl\nEteclVLWnFLaEhE/BjYC/cAdKaUR31JXC0r8PX8ZuCsiNjHwDpIbUko1e7fIiPg2sAJoj4idwJeA\nRqhOfvkJVUnK0GSuZSRJ42S4S1KGDHdJypDhLkkZMtwlKUOGuyRlyHCXpAwZ7pKUof8PXWvXK+hp\nUJ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a149efb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La précision est 0.942600896861\n",
      "\n",
      "L'AUC est 0.788073005683\n",
      "\n",
      "Le score moyen par 10 cross-validation est 0.880692786943\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-122c690987ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinal_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_bis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcomparaison_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparisons_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_bis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-7047b2630159>\u001b[0m in \u001b[0;36mcomparisons_tables\u001b[0;34m(data, target, modes, print_mode)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-1fcb3ce85a2f>\u001b[0m in \u001b[0;36mfinal_table\u001b[0;34m(data, target, col, algos, indexs, mode, print_mode)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprint_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mcvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'str(alg)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-1794f8123989>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, ylim, cvalidation, n_jobs, train_sizes, print_mode)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     train_sizes, train_scores, test_scores = learning_curve(\n\u001b[0;32m---> 50\u001b[0;31m         estimator, X, y, cv=cvalidation, n_jobs=n_jobs, train_sizes=train_sizes)\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtrain_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m             verbose, parameters=None, fit_params=None, return_train_score=True)\n\u001b[0;32m-> 1128\u001b[0;31m             for train, test in train_test_proportions)\n\u001b[0m\u001b[1;32m   1129\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0mn_cv_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mn_unique_ticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_tfidf = final_table(tfidf, target_bis, print_mode=False)\n",
    "comparaison_tfidf = comparisons_tables(tfidf,target=target_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc = 100\n",
    "\n",
    "svd = TruncatedSVD(n_components=nc, n_iter=10, random_state=42)\n",
    "svd.fit(tfidf) \n",
    "SVD = pd.DataFrame(svd.transform(tfidf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_svd = final_table(SVD, target, print_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
